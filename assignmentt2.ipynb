{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a9948c7-dbc6-4477-8a55-11ab3e7d92d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Using cached pyttsx3-2.98-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting comtypes (from pyttsx3)\n",
      "  Using cached comtypes-1.4.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Using cached pypiwin32-223-py3-none-any.whl.metadata (236 bytes)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Using cached pyttsx3-2.98-py3-none-any.whl (34 kB)\n",
      "Using cached comtypes-1.4.8-py3-none-any.whl (229 kB)\n",
      "Using cached pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Installing collected packages: pypiwin32, comtypes, pyttsx3\n",
      "Successfully installed comtypes-1.4.8 pypiwin32-223 pyttsx3-2.98\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ee70a97-05b5-4c0a-ac73-530612699c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting speechrecognition\n",
      "  Using cached SpeechRecognition-3.12.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.47.1)\n",
      "Collecting gTTS\n",
      "  Using cached gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from speechrecognition) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading SpeechRecognition-3.12.0-py3-none-any.whl (32.8 MB)\n",
      "   ---------------------------------------- 0.0/32.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/32.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/32.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/32.8 MB 1.3 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 1.0/32.8 MB 1.6 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 1.6/32.8 MB 1.7 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 2.1/32.8 MB 1.8 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 2.4/32.8 MB 1.8 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.1/32.8 MB 2.0 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 4.2/32.8 MB 2.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 5.0/32.8 MB 2.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 6.3/32.8 MB 2.9 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 6.8/32.8 MB 2.9 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 7.6/32.8 MB 2.9 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 8.1/32.8 MB 3.0 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 8.7/32.8 MB 2.9 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 9.4/32.8 MB 3.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 10.5/32.8 MB 3.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 11.3/32.8 MB 3.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 12.1/32.8 MB 3.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 13.1/32.8 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 14.2/32.8 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 15.2/32.8 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 16.3/32.8 MB 3.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 17.0/32.8 MB 3.5 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 17.8/32.8 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 18.4/32.8 MB 3.5 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 19.4/32.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 20.2/32.8 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 21.0/32.8 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 21.8/32.8 MB 3.6 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 22.5/32.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 23.6/32.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 24.4/32.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 24.9/32.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 25.4/32.8 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 26.5/32.8 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 27.8/32.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 28.6/32.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 29.9/32.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 30.7/32.8 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 31.5/32.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.5/32.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.8/32.8 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: speechrecognition, gTTS\n",
      "Successfully installed gTTS-2.5.4 speechrecognition-3.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install speechrecognition transformers gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fd9a49-a82b-4c37-9f99-82e9e86b851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a9bda-99a4-432b-9926-8dd9184ff8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: Sorry, I didn't understand that.\n",
      "LLM Response: Sorry, I didn't understand that. Just that the two were friends and not enemies, because the two of us were never friends.\n",
      "\n",
      "The thing that I am very frustrated about is what we are being taught. The students in our classes who\n",
      "Speaking: Sorry, I didn't understand that. Just that the two were friends and not enemies, because the two of us were never friends.\n",
      "\n",
      "The thing that I am very frustrated about is what we are being taught. The students in our classes who\n",
      "Say something...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: Sorry, I didn't understand that.\n",
      "LLM Response: Sorry, I didn't understand that. I didn't think that you could get yourself away from being a slave to my cock. It seemed so dangerous but you were so ready to do it! But I won't let you slip into that trap!\n",
      "Speaking: Sorry, I didn't understand that. I didn't think that you could get yourself away from being a slave to my cock. It seemed so dangerous but you were so ready to do it! But I won't let you slip into that trap!\n",
      "Say something...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User said: hello\n",
      "User Input: hello\n",
      "LLM Response: hello or the right hand side. Let's say the left hand is 1/2 inch, but the right hand side is 5/8 inches.\n",
      "\n",
      "So we have 2 x 9\" x 100 m. We can now make the above model\n",
      "Speaking: hello or the right hand side. Let's say the left hand is 1/2 inch, but the right hand side is 5/8 inches.\n",
      "\n",
      "So we have 2 x 9\" x 100 m. We can now make the above model\n",
      "Say something...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User said: good morning\n",
      "User Input: good morning\n",
      "LLM Response: good morning\" and he didn't get to do it. He kept going and his friends had to call him back. \"He looked like nothing I'd ever seen before.\"\n",
      "\n",
      "It wasn't just that, as early as October 2008, Mr\n",
      "Speaking: good morning\" and he didn't get to do it. He kept going and his friends had to call him back. \"He looked like nothing I'd ever seen before.\"\n",
      "\n",
      "It wasn't just that, as early as October 2008, Mr\n",
      "Say something...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User said: my name is Varshini\n",
      "User Input: my name is Varshini\n",
      "LLM Response: my name is Varshini in Hindi/Sanskrit. When making a call to the name, he always takes pictures out of his smartphone, and always takes that picture with me (like after having a baby while taking pictures on my cellphone).\n",
      "Speaking: my name is Varshini in Hindi/Sanskrit. When making a call to the name, he always takes pictures out of his smartphone, and always takes that picture with me (like after having a baby while taking pictures on my cellphone).\n",
      "Say something...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: Sorry, I didn't understand that.\n",
      "LLM Response: Sorry, I didn't understand that. The rest is history.\n",
      "\n",
      "For a long time, I knew that a majority of the New Democrats might get elected, but I had no idea where their seat was on the ballot. I knew that only\n",
      "Speaking: Sorry, I didn't understand that. The rest is history.\n",
      "\n",
      "For a long time, I knew that a majority of the New Democrats might get elected, but I had no idea where their seat was on the ballot. I knew that only\n",
      "Say something...\n",
      "Listening...\n",
      "Recognizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: Sorry, I didn't understand that.\n",
      "LLM Response: Sorry, I didn't understand that. \"I do understand now.\"\n",
      "\n",
      "Harry's head was spinning from shock and panic to his head spinning from the thought.\n",
      "\n",
      "He stared at the door, unable to tell if it had swung open enough\n",
      "Speaking: Sorry, I didn't understand that. \"I do understand now.\"\n",
      "\n",
      "Harry's head was spinning from shock and panic to his head spinning from the thought.\n",
      "\n",
      "He stared at the door, unable to tell if it had swung open enough\n",
      "Say something...\n",
      "Listening...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyttsx3 \n",
    "import speech_recognition as sr \n",
    "from transformers import pipeline \n",
    "import time\n",
    "llm = pipeline(\"text-generation\", model=\"gpt2\", device=-1)\n",
    "tts_engine = pyttsx3.init()\n",
    "def recognize_speech():\n",
    "    \"\"\"Recognize speech from the microphone and return text.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source) \n",
    "        try:\n",
    "            audio = recognizer.listen(source)\n",
    "            print(\"Recognizing...\")\n",
    "            text = recognizer.recognize_google(audio)  \n",
    "            print(f\"User said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Sorry, I didn't understand that.\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Speech recognition error: {e}\"\n",
    "def generate_response(input_text):\n",
    "    \"\"\"Generate a response using the LLM.\"\"\"\n",
    "    print(f\"User Input: {input_text}\")\n",
    "    response = llm(input_text, max_length=50, truncation=True)[0][\"generated_text\"]\n",
    "    print(f\"LLM Response: {response}\")\n",
    "    return response\n",
    "def speak_response(response_text):\n",
    "    \"\"\"Convert text response to speech.\"\"\"\n",
    "    print(f\"Speaking: {response_text}\")\n",
    "    tts_engine.say(response_text)  \n",
    "    tts_engine.runAndWait() \n",
    "def main():\n",
    "    while True:\n",
    "        print(\"Say something...\")\n",
    "        user_input = recognize_speech()  \n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Exiting...\")\n",
    "            speak_response(\"Goodbye!\")\n",
    "            break\n",
    "        response = generate_response(user_input)\n",
    "        speak_response(response)\n",
    "        \n",
    "        time.sleep(1)  \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f3221-9fac-4914-b325-a37953937235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
